{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10100 clips\n",
      "Processed 10200 clips\n",
      "Processed 10300 clips\n",
      "Processed 10400 clips\n",
      "Processed 10500 clips\n",
      "Processed 10600 clips\n",
      "Processed 10700 clips\n",
      "Processed 10800 clips\n",
      "Processed 10900 clips\n",
      "Processed 11000 clips\n",
      "Processed 11100 clips\n",
      "Processed 11200 clips\n",
      "Processed 11300 clips\n",
      "Processed 11400 clips\n",
      "Processed 11500 clips\n",
      "Processed 11600 clips\n",
      "Processed 11700 clips\n",
      "Processed 11800 clips\n",
      "Processed 11900 clips\n",
      "Processed 12000 clips\n",
      "Processed 12100 clips\n",
      "Processed 12200 clips\n",
      "Processed 12300 clips\n",
      "Processed 12400 clips\n",
      "Processed 12500 clips\n",
      "Processed 12600 clips\n",
      "Processed 12700 clips\n",
      "Processed 12800 clips\n",
      "Processed 12900 clips\n",
      "Processed 13000 clips\n",
      "Processed 13100 clips\n",
      "Processed 13200 clips\n",
      "Processed 13300 clips\n",
      "Processed 13400 clips\n",
      "Processed 13500 clips\n",
      "Processed 13600 clips\n",
      "Processed 13700 clips\n",
      "Processed 13800 clips\n",
      "Processed 13900 clips\n",
      "Processed 14000 clips\n",
      "Processed 14100 clips\n",
      "Processed 14200 clips\n",
      "Processed 14300 clips\n",
      "Processed 14400 clips\n",
      "Processed 14500 clips\n",
      "Processed 14600 clips\n",
      "Processed 14700 clips\n",
      "Processed 14800 clips\n",
      "Processed 14900 clips\n",
      "Processed 15000 clips\n",
      "Processed 15100 clips\n",
      "Processed 15200 clips\n",
      "Processed 15300 clips\n",
      "Processed 15400 clips\n",
      "Processed 15500 clips\n",
      "Processed 15600 clips\n",
      "Processed 15700 clips\n",
      "Processed 15800 clips\n",
      "Processed 15900 clips\n",
      "Processed 16000 clips\n",
      "Processed 16100 clips\n",
      "Processed 16200 clips\n",
      "Processed 16300 clips\n",
      "Processed 16400 clips\n",
      "Processed 16500 clips\n",
      "Processed 16600 clips\n",
      "Processed 16700 clips\n",
      "Processed 16800 clips\n",
      "Processed 16900 clips\n",
      "Processed 17000 clips\n",
      "Processed 17100 clips\n",
      "Processed 17200 clips\n",
      "Processed 17300 clips\n",
      "Processed 17400 clips\n",
      "Processed 17500 clips\n",
      "Processed 17600 clips\n",
      "Processed 17700 clips\n",
      "Processed 17800 clips\n",
      "Processed 17900 clips\n",
      "Processed 18000 clips\n",
      "Processed 18100 clips\n",
      "Processed 18200 clips\n",
      "Processed 18300 clips\n",
      "Processed 18400 clips\n",
      "Processed 18500 clips\n",
      "Processed 18600 clips\n",
      "Processed 18700 clips\n",
      "Processed 18800 clips\n",
      "Processed 18900 clips\n",
      "Processed 19000 clips\n",
      "Processed 19100 clips\n",
      "Processed 19200 clips\n",
      "Processed 19300 clips\n",
      "Processed 19400 clips\n",
      "Processed 19500 clips\n",
      "Processed 19600 clips\n",
      "Processed 19700 clips\n",
      "Processed 19800 clips\n",
      "Processed 19900 clips\n",
      "Processed 20000 clips\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import getopt\n",
    "import sys\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "import constants as c\n",
    "from utils import process_clip\n",
    "\n",
    "\n",
    "def process_training_data(num_clips):\n",
    "    \"\"\"\n",
    "    Processes random training clips from the full training data. Saves to TRAIN_DIR_CLIPS by\n",
    "    default.\n",
    "\n",
    "    @param num_clips: The number of clips to process. Default = 5000000 (set in __main__).\n",
    "\n",
    "    @warning: This can take a couple of hours to complete with large numbers of clips.\n",
    "    \"\"\"\n",
    "    num_prev_clips = len(glob(c.TRAIN_DIR_CLIPS + '*'))\n",
    "\n",
    "    for clip_num in range(num_prev_clips, num_clips + num_prev_clips):\n",
    "        clip = process_clip()\n",
    "\n",
    "        np.savez_compressed(c.TRAIN_DIR_CLIPS + str(clip_num), clip)\n",
    "\n",
    "        if (clip_num + 1) % 100 == 0: print('Processed %d clips' % (clip_num + 1))\n",
    "\n",
    "\n",
    "def usage():\n",
    "    print('Options:')\n",
    "    print('-n/--num_clips= <# clips to process for training> (Default = 5000000)')\n",
    "    print('-t/--train_dir= <Directory of full training frames>')\n",
    "    print('-c/--clips_dir= <Save directory for processed clips>')\n",
    "    print(\"                (I suggest making this a hidden dir so the filesystem doesn't freeze\")\n",
    "    print(\"                 with so many files. DON'T `ls` THIS DIRECTORY!)\")\n",
    "    print('-o/--overwrite  (Overwrites the previous data in clips_dir)')\n",
    "    print('-H/--help       (Prints usage)')\n",
    "\n",
    "\n",
    "def main():\n",
    "    ##\n",
    "    # Handle command line input\n",
    "    ##\n",
    "\n",
    "    num_clips = 10000\n",
    "\n",
    "    try:\n",
    "        opts, _ = getopt.getopt(sys.argv[1:], 'fn:t:c:oH',\n",
    "                                ['fwhat','num_clips=', 'train_dir=', 'clips_dir=', 'overwrite', 'help'])\n",
    "    except getopt.GetoptError:\n",
    "        usage()\n",
    "        sys.exit(2)\n",
    "\n",
    "#     opts = [('-t', '../Data/Ms_Pacman/Train')]\n",
    "    \n",
    "    for opt, arg in opts:\n",
    "        if opt in ('-n', '--num_clips'):\n",
    "            num_clips = int(arg)\n",
    "        if opt in ('-t', '--train_dir'):\n",
    "            c.TRAIN_DIR = c.get_dir(arg)\n",
    "        if opt in ('-c', '--clips_dir'):\n",
    "            c.TRAIN_DIR_CLIPS = c.get_dir(arg)\n",
    "        if opt in ('-o', '--overwrite'):\n",
    "            c.clear_dir(c.TRAIN_DIR_CLIPS)\n",
    "        if opt in ('-H', '--help'):\n",
    "            usage()\n",
    "            sys.exit(2)\n",
    "\n",
    "    # set train frame dimensions\n",
    "    assert os.path.exists(c.TRAIN_DIR)\n",
    "    c.FULL_HEIGHT, c.FULL_WIDTH = c.get_train_frame_dims()\n",
    "\n",
    "    ##\n",
    "    # Process data for training\n",
    "    ##\n",
    "\n",
    "    process_training_data(num_clips)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy==1.2.0\n",
      "  Downloading scipy-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (26.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.6 MB 19.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from scipy==1.2.0) (1.18.1)\n",
      "\u001b[31mERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-privacy 0.5.1 has requirement tensorflow-estimator>=2.3.0, but you'll have tensorflow-estimator 2.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-gpu 2.1.0 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: sklearn-pandas 2.0.3 has requirement pandas>=1.0.5, but you'll have pandas 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: sklearn-pandas 2.0.3 has requirement scikit-learn>=0.23.0, but you'll have scikit-learn 0.22.2.post1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: sklearn-pandas 2.0.3 has requirement scipy>=1.4.1, but you'll have scipy 1.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: plotnine 0.7.1 has requirement pandas>=1.1.0, but you'll have pandas 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pandas-profiling 2.9.0 has requirement matplotlib>=3.2.0, but you'll have matplotlib 3.1.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pandas-profiling 2.9.0 has requirement pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3, but you'll have pandas 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pandas-profiling 2.9.0 has requirement scipy>=1.4.1, but you'll have scipy 1.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pandas-profiling 2.9.0 has requirement seaborn>=0.10.1, but you'll have seaborn 0.10.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mlxtend 0.17.3 has requirement scipy>=1.2.1, but you'll have scipy 1.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: kapre 0.3.4 has requirement numpy>=1.18.5, but you'll have numpy 1.18.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: imbalanced-learn 0.7.0 has requirement scikit-learn>=0.23, but you'll have scikit-learn 0.22.2.post1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: gym 0.17.3 has requirement pyglet<=1.5.0,>=1.4.0, but you'll have pyglet 1.5.10 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: featuretools 0.21.0 has requirement dask[dataframe]>=2.12.0, but you'll have dask 2.11.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fastai 2.1.5 has requirement torch>=1.7.0, but you'll have torch 1.5.1+cu101 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fastai 2.1.5 has requirement torchvision>=0.8, but you'll have torchvision 0.6.1+cu101 which is incompatible.\u001b[0m\n",
      "Installing collected packages: scipy\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "Successfully installed scipy-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy==1.2.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
